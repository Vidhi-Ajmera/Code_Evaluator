---

# ğŸš€ Code Evaluator  

ğŸ” **AI-Based Code Evaluator** - A powerful AI-powered system designed for automated code evaluation, enhancing efficiency in technical assessments and coding competitions.  

## ğŸ“Œ Project Overview  

The **Code Evaluator** is an intelligent system that allows evaluators to create coding contests, assess code submissions, and provide real-time feedback. The system supports multiple programming languages and automates the grading process using AI-based techniques.  

This project is ideal for:  
âœ”ï¸ **Technical Evaluation** - Automate candidate code evaluations.  
âœ”ï¸ **Contests** - Conduct coding competitions with instant grading.  
âœ”ï¸ **Education** - Help students learn programming with AI-driven feedback.  

---

## ğŸŒ Live Project Link  

ğŸ”— **[Project Demo](https://code-evaluator-frontend.vercel.app/)**  

---

## âœ¨ Features  

âœ… **Multi-Language Support** - Supports Python, Java, C++, and more.  
âœ… **Automated Code Evaluation** - Executes code with predefined test cases.  
âœ… **Real-Time Feedback** - Provides immediate results and analysis.  
âœ… **AI-Powered Proctoring** - Monitors participants during contests.  
âœ… **Plagiarism Detection** - Ensures the originality of code submissions.  
âœ… **Contest Management** - Allows evaluators to create and manage coding contests.  
âœ… **Interactive Dashboard** - Displays participant performance and rankings.  

---

## ğŸ›  Installation & Setup  

### 1ï¸âƒ£ Clone the Repository  

```bash
git clone https://github.com/Vidhi-Ajmera/Code_Evaluator.git
cd Code_Evaluator
```

### 2ï¸âƒ£ Install Dependencies  

#### ğŸ“Œ Backend Setup (Python)  

```bash
cd backend
pip install -r requirements.txt
python main.py
```

#### ğŸ“Œ Frontend Setup (React.js)  

```bash
cd frontend
npm install
npm start
```

---

## ğŸ”§ Usage  

### ğŸ¯ **For Evaluators (Admin Panel)**  
1ï¸âƒ£ **Login** as an evaluator.  
2ï¸âƒ£ **Create** a new coding contest by specifying the number of questions.  
3ï¸âƒ£ **Define** problem statements, test cases, and scoring criteria.  
4ï¸âƒ£ **Share** the contest link with participants.  
5ï¸âƒ£ **Monitor submissions**, view results, and analyze participant performance.  

### ğŸ¯ **For Participants (Contestants)**  
1ï¸âƒ£ **Sign up** and join an active contest.  
2ï¸âƒ£ **Select** a problem statement and write your code.  
3ï¸âƒ£ **Submit** your solution for evaluation.  
4ï¸âƒ£ **Receive feedback**, including test case results and scores.  
5ï¸âƒ£ **Check the leaderboard** to see your ranking.  

---

## ğŸ“‚ Project Structure  

```
Code_Evaluator/
â”‚â”€â”€ backend/        # AI-based evaluation engine (Flask/FastAPI)
â”‚   â”œâ”€â”€ models/     # ML models for code evaluation
â”‚   â”œâ”€â”€ routes/     # API endpoints
â”‚   â”œâ”€â”€ tests/      # Backend unit tests
â”‚   â”œâ”€â”€ main.py     # Backend entry point
â”‚
â”‚â”€â”€ frontend/       # React-based web application
â”‚   â”œâ”€â”€ src/        # React components and pages
â”‚   â”œâ”€â”€ public/     # Static assets
â”‚   â”œâ”€â”€ package.json # Frontend dependencies
â”‚
â”‚â”€â”€ docs/           # Documentation and API specifications
â”‚â”€â”€ tests/          # Integration tests
â”‚â”€â”€ .gitignore      # Git ignore file
â”‚â”€â”€ README.md       # Project documentation
```

---

## ğŸš€ Future Enhancements  
ğŸ”¹ **AI-powered hints and recommendations** for incorrect code submissions.  
ğŸ”¹ **Enhanced plagiarism detection** using deep learning models.  
ğŸ”¹ **Live coding environment** for real-time collaboration and debugging.  

---

## ğŸ‘¥ Contributors  

- **Vidhi Ajmera**  
- **Anshika Tripathi**  
- **Deepak Shukla**  
- **Ekta Agrawal**  
- **Saubhagya Sharma**  


---
