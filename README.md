---

# 🚀 Code Evaluator  

🔍 **AI-Based Code Evaluator** - A powerful AI-powered system designed for automated code evaluation, enhancing efficiency in technical assessments and coding competitions.  

## 📌 Project Overview  

The **Code Evaluator** is an intelligent system that allows evaluators to create coding contests, assess code submissions, and provide real-time feedback. The system supports multiple programming languages and automates the grading process using AI-based techniques.  

This project is ideal for:  
✔️ **Technical Evaluation** - Automate candidate code evaluations.  
✔️ **Contests** - Conduct coding competitions with instant grading.  
✔️ **Education** - Help students learn programming with AI-driven feedback.  

---

## 🌐 Live Project Link  

🔗 **[Project Demo](https://code-evaluator-frontend.vercel.app/)**  

---

## ✨ Features  

✅ **Multi-Language Support** - Supports Python, Java, C++, and more.  
✅ **Automated Code Evaluation** - Executes code with predefined test cases.  
✅ **Real-Time Feedback** - Provides immediate results and analysis.  
✅ **AI-Powered Proctoring** - Monitors participants during contests.  
✅ **Plagiarism Detection** - Ensures the originality of code submissions.  
✅ **Contest Management** - Allows evaluators to create and manage coding contests.  
✅ **Interactive Dashboard** - Displays participant performance and rankings.  

---

## 🛠 Installation & Setup  

### 1️⃣ Clone the Repository  

```bash
git clone https://github.com/Vidhi-Ajmera/Code_Evaluator.git
cd Code_Evaluator
```

### 2️⃣ Install Dependencies  

#### 📌 Backend Setup (Python)  

```bash
cd backend
pip install -r requirements.txt
python main.py
```

#### 📌 Frontend Setup (React.js)  

```bash
cd frontend
npm install
npm start
```

---

## 🔧 Usage  

### 🎯 **For Evaluators (Admin Panel)**  
1️⃣ **Login** as an evaluator.  
2️⃣ **Create** a new coding contest by specifying the number of questions.  
3️⃣ **Define** problem statements, test cases, and scoring criteria.  
4️⃣ **Share** the contest link with participants.  
5️⃣ **Monitor submissions**, view results, and analyze participant performance.  

### 🎯 **For Participants (Contestants)**  
1️⃣ **Sign up** and join an active contest.  
2️⃣ **Select** a problem statement and write your code.  
3️⃣ **Submit** your solution for evaluation.  
4️⃣ **Receive feedback**, including test case results and scores.  
5️⃣ **Check the leaderboard** to see your ranking.  

---

## 📂 Project Structure  

```
Code_Evaluator/
│── backend/        # AI-based evaluation engine (Flask/FastAPI)
│   ├── models/     # ML models for code evaluation
│   ├── routes/     # API endpoints
│   ├── tests/      # Backend unit tests
│   ├── main.py     # Backend entry point
│
│── frontend/       # React-based web application
│   ├── src/        # React components and pages
│   ├── public/     # Static assets
│   ├── package.json # Frontend dependencies
│
│── docs/           # Documentation and API specifications
│── tests/          # Integration tests
│── .gitignore      # Git ignore file
│── README.md       # Project documentation
```

---

## 🚀 Future Enhancements  
🔹 **AI-powered hints and recommendations** for incorrect code submissions.  
🔹 **Enhanced plagiarism detection** using deep learning models.  
🔹 **Live coding environment** for real-time collaboration and debugging.  

---

## 👥 Contributors  

- **Vidhi Ajmera**  
- **Anshika Tripathi**  
- **Deepak Shukla**  
- **Ekta Agrawal**  
- **Saubhagya Sharma**  


---
